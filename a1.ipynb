{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Essential skills for junior-level positions:\n",
      "junior: 1.0000\n",
      "java: 0.1246\n",
      "python: 0.0956\n",
      "ruby: 0.0832\n",
      "mysql: 0.0583\n",
      "oracle: 0.0482\n",
      "mongodb: 0.0228\n",
      "snowflake: 0.0221\n",
      "postgresql: 0.0181\n",
      "scala: 0.0161\n",
      "elasticsearch: 0.0147\n",
      "swift: 0.0103\n",
      "redis: 0.0071\n",
      "sqlite: 0.0062\n",
      "rust: 0.0041\n",
      "kotlin: 0.0017\n",
      "c: 0.0000\n",
      "julia: 0.0000\n",
      "lua: 0.0000\n",
      "microsoft sql server: 0.0000\n",
      "ibm db2: 0.0000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Load the job descriptions from the CSV file\n",
    "file_path = 'resources/software_developer_united_states_1971_20191023_1.csv'  # Update this path to the correct location\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Check if 'string' column is present; adapt column name if necessary\n",
    "df['string'] = df['job_title']+ df['job_description']\n",
    "\n",
    "# Define the keywords (programming languages and databases) and the term 'junior'\n",
    "keywords = [\n",
    "    'java', 'python', 'c', 'kotlin', 'swift', 'rust', 'ruby', 'scala',\n",
    "    'julia', 'lua', 'oracle', 'mysql', 'microsoft sql server', 'postgresql',\n",
    "    'mongodb', 'redis', 'snowflake', 'elasticsearch', 'ibm db2', 'sqlite', 'junior'\n",
    "]\n",
    "\n",
    "# Vectorize the job descriptions with the defined keywords\n",
    "vectorizer = TfidfVectorizer(stop_words='english', vocabulary=keywords)\n",
    "tfidf_matrix = vectorizer.fit_transform(df['string'])\n",
    "\n",
    "# Extract the row corresponding to 'junior' as a vector\n",
    "junior_vector = tfidf_matrix[:, keywords.index('junior')]\n",
    "\n",
    "# Calculate cosine similarity between 'junior' and all other keywords\n",
    "cosine_sim_with_junior = cosine_similarity(junior_vector.T, tfidf_matrix.T)\n",
    "\n",
    "# Extract the similarity scores for each keyword with 'junior'\n",
    "similarity_scores = cosine_sim_with_junior.flatten()\n",
    "\n",
    "# Pair the keywords (excluding 'junior') with their scores\n",
    "keyword_similarity = list(zip(keywords, similarity_scores))\n",
    "\n",
    "# Sort by relevance (descending order)\n",
    "sorted_keyword_similarity = sorted(keyword_similarity, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Display the top programming languages and databases related to 'junior'\n",
    "print(\"Essential skills for junior-level positions:\")\n",
    "for keyword, score in sorted_keyword_similarity:\n",
    "    print(f\"{keyword}: {score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top complementary programming languages for 'java':\n",
      "python    0.232416\n",
      "scala     0.097139\n",
      "ruby      0.083994\n",
      "swift     0.042116\n",
      "kotlin    0.030037\n",
      "Name: java, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Load the job descriptions from the CSV file\n",
    "file_path = 'resources/software_developer_united_states_1971_20191023_1.csv'  # Update this path\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Check if 'string' column is present; adapt column name if necessary\n",
    "df['string'] = df['job_title']+ df['job_description']\n",
    "\n",
    "# Define the programming languages\n",
    "programming_languages = [\n",
    "    'java', 'python', 'c', 'kotlin', 'swift', 'rust', 'ruby', 'scala',\n",
    "    'julia', 'lua'\n",
    "]\n",
    "\n",
    "# Vectorize the job descriptions with the defined programming languages\n",
    "vectorizer = TfidfVectorizer(stop_words='english', vocabulary=programming_languages)\n",
    "tfidf_matrix = vectorizer.fit_transform(df['string'])\n",
    "\n",
    "# Calculate the cosine similarity between all programming languages\n",
    "cosine_sim_matrix = cosine_similarity(tfidf_matrix.T)\n",
    "\n",
    "# Convert similarity matrix to a DataFrame for easier analysis\n",
    "cosine_sim_df = pd.DataFrame(\n",
    "    cosine_sim_matrix, \n",
    "    index=programming_languages, \n",
    "    columns=programming_languages\n",
    ")\n",
    "\n",
    "# Primary language (select based on initial analysis or top importance score)\n",
    "primary_language = 'java'  # Replace with your choice\n",
    "\n",
    "# Sort complementary languages by similarity score\n",
    "complementary_languages = cosine_sim_df[primary_language].sort_values(ascending=False)[1:]\n",
    "\n",
    "# Display recommendations\n",
    "print(f\"Top complementary programming languages for '{primary_language}':\")\n",
    "print(complementary_languages.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# P(Senior | Skill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database proficiencies best suited for senior software developers:\n",
      "Skill\n",
      "oracle                  0.315379\n",
      "postgresql              0.253731\n",
      "sqlite                  0.239332\n",
      "mongodb                 0.215014\n",
      "redis                   0.214495\n",
      "elasticsearch           0.198396\n",
      "ibm db2                 0.195336\n",
      "snowflake               0.170744\n",
      "microsoft sql server    0.145755\n",
      "mysql                   0.144912\n",
      "Name: P(Senior | Skill), dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# Define the prior probabilities\n",
    "p_senior = 0.07  # P(Senior Software Developer)\n",
    "p_not_senior = 1 - p_senior  # P(Not Senior)\n",
    "\n",
    "# Define database skills and their probabilities (assumed distribution)\n",
    "database_skills = [\n",
    "    'oracle', 'mysql', 'microsoft sql server', 'postgresql', 'mongodb',\n",
    "    'redis', 'snowflake', 'elasticsearch', 'ibm db2', 'sqlite'\n",
    "]\n",
    "\n",
    "p_skill = {  # P(Skill), pre-calculated frequencies\n",
    "    'oracle': 1392 / 7583,\n",
    "    'mysql': 667 / 7583,\n",
    "    'microsoft sql server': 868 / 7583,\n",
    "    'postgresql': 261 / 7583,\n",
    "    'mongodb': 296 / 7583,\n",
    "    'redis': 106 / 7583,\n",
    "    'snowflake': 15 / 7583,\n",
    "    'elasticsearch': 161 / 7583,\n",
    "    'ibm db2': 48 / 7583,\n",
    "    'sqlite': 28 / 7583\n",
    "}\n",
    "\n",
    "# Assume P(Skill | Senior) follows a distribution (adjust these based on domain knowledge)\n",
    "np.random.seed(42)  # For reproducibility\n",
    "p_skill_given_senior = {skill: np.random.uniform(0.5, 0.9) for skill in database_skills}\n",
    "p_skill_given_not_senior = {skill: np.random.uniform(0.1, 0.4) for skill in database_skills}\n",
    "\n",
    "# Monte Carlo Simulation\n",
    "iterations = 10_000\n",
    "results = []\n",
    "\n",
    "for _ in range(iterations):\n",
    "    for skill in database_skills:\n",
    "        # P(Skill) calculation\n",
    "        p_skill_combined = (\n",
    "            p_skill_given_senior[skill] * p_senior +\n",
    "            p_skill_given_not_senior[skill] * p_not_senior\n",
    "        )\n",
    "        \n",
    "        # Bayes' theorem to calculate P(Senior | Skill)\n",
    "        p_senior_given_skill = (\n",
    "            p_skill_given_senior[skill] * p_senior / p_skill_combined\n",
    "        )\n",
    "        \n",
    "        results.append((skill, p_senior_given_skill))\n",
    "\n",
    "# Summarize the results\n",
    "results_df = pd.DataFrame(results, columns=['Skill', 'P(Senior | Skill)'])\n",
    "mean_results = results_df.groupby('Skill')['P(Senior | Skill)'].mean().sort_values(ascending=False)\n",
    "\n",
    "# Display the most relevant database proficiencies for senior roles\n",
    "print(\"Database proficiencies best suited for senior software developers:\")\n",
    "print(mean_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# P(Skill | senior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database proficiencies best suited for senior software developers (P(Skill | Senior)):\n",
      "Skill\n",
      "oracle                  1.704082\n",
      "microsoft sql server    1.296412\n",
      "mysql                   1.106141\n",
      "postgresql              0.363595\n",
      "mongodb                 0.313620\n",
      "elasticsearch           0.256743\n",
      "redis                   0.112308\n",
      "ibm db2                 0.066957\n",
      "sqlite                  0.041315\n",
      "snowflake               0.014786\n",
      "Name: P(Skill | Senior), dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np# Prior probability for senior software developer\n",
    "\n",
    "p_senior = 0.07  # P(Senior)\n",
    "p_skill = {  # P(Skill), pre-calculated frequencies\n",
    "    'oracle': 1392 / 7583,\n",
    "    'mysql': 667 / 7583,\n",
    "    'microsoft sql server': 868 / 7583,\n",
    "    'postgresql': 261 / 7583,\n",
    "    'mongodb': 296 / 7583,\n",
    "    'redis': 106 / 7583,\n",
    "    'snowflake': 15 / 7583,\n",
    "    'elasticsearch': 161 / 7583,\n",
    "    'ibm db2': 48 / 7583,\n",
    "    'sqlite': 28 / 7583\n",
    "}\n",
    "\n",
    "# Assume P(Senior | Skill) is based on a uniform distribution (to be refined if real data is available)\n",
    "np.random.seed(42)  # For reproducibility\n",
    "p_senior_given_skill = {skill: np.random.uniform(0.5, 0.9) for skill in p_skill.keys()}\n",
    "\n",
    "# Monte Carlo simulation to compute P(Skill | Senior)\n",
    "iterations = 10_000\n",
    "results = []\n",
    "\n",
    "for _ in range(iterations):\n",
    "    for skill in p_skill.keys():\n",
    "        # Simulate P(Senior | Skill) (fixed in this case, but could vary in real scenarios)\n",
    "        simulated_p_senior_given_skill = p_senior_given_skill[skill]\n",
    "        \n",
    "        # Calculate P(Skill | Senior) using Bayes' theorem\n",
    "        p_skill_given_senior = (\n",
    "            simulated_p_senior_given_skill * p_skill[skill] / p_senior\n",
    "        )\n",
    "        \n",
    "        results.append((skill, p_skill_given_senior))\n",
    "\n",
    "# Summarize the results\n",
    "results_df = pd.DataFrame(results, columns=['Skill', 'P(Skill | Senior)'])\n",
    "mean_results = results_df.groupby('Skill')['P(Skill | Senior)'].mean().sort_values(ascending=False)\n",
    "\n",
    "# Display the result\n",
    "print(\"Database proficiencies best suited for senior software developers (P(Skill | Senior)):\")\n",
    "print(mean_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
